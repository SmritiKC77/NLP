{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da15753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be05810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'NLP', 'profanity_filter.ipynb', 'Profanity_filter_model.joblib', 'profanity_words']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "files = os.listdir(current_directory)\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883cf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('profanity_words/English_profanity_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e47848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then go to the village pump and suggest they c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ANTI GREEK NATIONALIS -WIKIPEDIA \\n\\nHi Alexik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Dis hoe wasnt dis violent on Lottery Ticket ðŸ˜‚ðŸ˜‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It is better for Atabay not helping the banned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"is in CamelCase.  \"\"SiCKO\"\" is not CamelCase,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_offensive                                               text\n",
       "0             0  Then go to the village pump and suggest they c...\n",
       "1             1  ANTI GREEK NATIONALIS -WIKIPEDIA \\n\\nHi Alexik...\n",
       "2             1     Dis hoe wasnt dis violent on Lottery Ticket ðŸ˜‚ðŸ˜‚\n",
       "3             0  It is better for Atabay not helping the banned...\n",
       "4             0  \"is in CamelCase.  \"\"SiCKO\"\" is not CamelCase,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bc97e",
   "metadata": {},
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaced08b",
   "metadata": {},
   "outputs": [],
   "source": [
    " df= df.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f60f72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20000 entries, 145949 to 118262\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   is_offensive  20000 non-null  int64 \n",
      " 1   text          20000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 468.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c378e8e",
   "metadata": {},
   "source": [
    "Text Preprocessing\n",
    "1. Remove special characters\n",
    "2. lowercasing\n",
    "3. Remove stop words\n",
    "4. Remove stop words\n",
    "5. Tokenization\n",
    "6. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a0a6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f16fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    clean_text = ' '.join(tokens)#text ma token lai join garya\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee35da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469ae3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_offensive'] = df['is_offensive'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8945674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_offensive</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145949</th>\n",
       "      <td>False</td>\n",
       "      <td>government openly poved guess could neutralize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57024</th>\n",
       "      <td>False</td>\n",
       "      <td>child adult oriented think mention omsi childr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120292</th>\n",
       "      <td>True</td>\n",
       "      <td>donnerkay surlyrevenant enraged lb mike brown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154052</th>\n",
       "      <td>True</td>\n",
       "      <td>lmfaoooooo im glad shorty aint twitter ig tryn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85086</th>\n",
       "      <td>True</td>\n",
       "      <td>happy valentine day big booty bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_offensive                                               text\n",
       "145949         False  government openly poved guess could neutralize...\n",
       "57024          False  child adult oriented think mention omsi childr...\n",
       "120292          True  donnerkay surlyrevenant enraged lb mike brown ...\n",
       "154052          True  lmfaoooooo im glad shorty aint twitter ig tryn...\n",
       "85086           True                happy valentine day big booty bitch"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad85870",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817c843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['text']\n",
    "y= df['is_offensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8851659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145949    government openly poved guess could neutralize...\n",
       "57024     child adult oriented think mention omsi childr...\n",
       "120292    donnerkay surlyrevenant enraged lb mike brown ...\n",
       "154052    lmfaoooooo im glad shorty aint twitter ig tryn...\n",
       "85086                   happy valentine day big booty bitch\n",
       "                                ...                        \n",
       "158636    well one came along defend sentence ill assume...\n",
       "10111     reply posted clark peer review page think good...\n",
       "35297                         ip note use endless ip number\n",
       "45837     also im concerned block technical sense shorta...\n",
       "118262    please add nonsense wikipedia considered vanda...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6675c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145949    False\n",
       "57024     False\n",
       "120292     True\n",
       "154052     True\n",
       "85086      True\n",
       "          ...  \n",
       "158636    False\n",
       "10111     False\n",
       "35297     False\n",
       "45837     False\n",
       "118262    False\n",
       "Name: is_offensive, Length: 20000, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbad7600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbeaf5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94e73313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3410ee9",
   "metadata": {},
   "source": [
    "tF- IDF is used for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ff7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e7d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_vectorized = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23a34c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 44850)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d27947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 44850)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fef2f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df5c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CalibratedClassifierCV(estimator=LinearSVC(class_weight=&#x27;balanced&#x27;, dual=False,\n",
       "                                           max_iter=100000, tol=0.01))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(estimator=LinearSVC(class_weight=&#x27;balanced&#x27;, dual=False,\n",
       "                                           max_iter=100000, tol=0.01))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(class_weight=&#x27;balanced&#x27;, dual=False, max_iter=100000, tol=0.01)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(class_weight=&#x27;balanced&#x27;, dual=False, max_iter=100000, tol=0.01)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "CalibratedClassifierCV(estimator=LinearSVC(class_weight='balanced', dual=False,\n",
       "                                           max_iter=100000, tol=0.01))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight=\"balanced\", dual=False, tol=1e-2, max_iter=int(1e5))\n",
    "cclf = CalibratedClassifierCV(model)\n",
    "cclf.fit(X_train_vectorized, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1647a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = cclf.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "910c5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score =accuracy_score(y_test,y_predict)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f37714b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Profanity_filter_model.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(cclf, 'Profanity_filter_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16b29755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "loaded_model = load('Profanity_filter_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb056218",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"Hey girl! If you donot complete a task by EOD I will kill you\",\n",
    "        \"I already had my breakfast\",\n",
    "        \"you are a dumbass\",\n",
    "        \"She is such a bitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bb525fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tx = vectorizer.transform(text)\n",
    "tx = loaded_model.predict(tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcc8e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab51c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c72311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
